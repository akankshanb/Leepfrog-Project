{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Preprocessing </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load training and eval data\n",
    "training = pd.read_csv(\"training.psv\", sep= \"|\")\n",
    "training['label'] = 'train'\n",
    "evals = pd.read_csv(\"eval.psv\", sep =\"|\")\n",
    "evals['label'] = 'eval'\n",
    "\n",
    "# Concatinate the two data frames and separate them by labelling either training or eval\n",
    "concat_df = pd.concat([training , evals], axis = 0,sort=False)\n",
    "\n",
    "#split course into course name and course number\n",
    "concat_df[['course','course_number']] = concat_df.course.str.split(\":\",expand = True,)\n",
    "\n",
    "#extract the training majors\n",
    "training_majors = training[['student_id','major']].drop_duplicates()\n",
    "\n",
    "#encode grades by value. 12 grades taken and rest are dropped\n",
    "concat_df['grade'] = concat_df.grade.replace(['A+','A','A-','B+','B','B-','C+','C','C-','D+','D','D-'],\n",
    "            [12, 11, 10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n",
    "\n",
    "#dropping the remaining grade entries\n",
    "dropped_grades = ['S','AUS','AUU','F','IP','N','P','U','R','WX','I']\n",
    "concat_df = concat_df[~concat_df['grade'].isin(dropped_grades)]\n",
    "\n",
    "\n",
    "#grouping entries by course and label\n",
    "concat_df.grade = concat_df.grade.astype(int)\n",
    "concat_df.course_number = concat_df.course_number.astype(int)\n",
    "\n",
    "#finding the difficulty of a course by using the course number's first digit\n",
    "concat_df['difficulty']= (concat_df.course_number/100).astype(int)\n",
    "concat_df.difficulty = concat_df.difficulty.astype(int)\n",
    "\n",
    "#now grouping data on the basis of student ids\n",
    "#taking mean of the weighted grades, maximum of the course diificulty and freq of the number of times\n",
    "#a course was taken by a student in all years\n",
    "concat_df['freq'] = 1\n",
    "grouped = concat_df.groupby(by=['student_id','course','label'], as_index=False).agg({'grade':np.mean, 'freq':np.sum, 'difficulty':np.max})\n",
    "\n",
    "#now sorting the data on the basis of frequency of a course taken\n",
    "sorted_df = grouped.sort_values(['student_id', 'freq'], ascending=False)\n",
    "\n",
    "#taking the first row for each student id. I will train on this reduced dataset\n",
    "concat_full = sorted_df.groupby('student_id', as_index=False).first().reset_index()\n",
    "\n",
    "#OneHot encoding course\n",
    "concat_full['course'] = pd.Categorical(concat_full['course'])\n",
    "\n",
    "dfDummies = pd.get_dummies(concat_full['course'], prefix = 'course_')\n",
    "\n",
    "concat_full = pd.concat([concat_full, dfDummies], axis=1)\n",
    "\n",
    "#OneHot encoding diificulty\n",
    "concat_full['difficulty'] = pd.Categorical(concat_full['difficulty'])\n",
    "\n",
    "dfDummies = pd.get_dummies(concat_full['difficulty'], prefix = 'diff_')\n",
    "\n",
    "concat_full = pd.concat([concat_full, dfDummies], axis=1)\n",
    "\n",
    "#splitting the concatenated data back to training and eval on the basis of label\n",
    "training = concat_full[concat_full.label == 'train']\n",
    "testing = concat_full[concat_full.label == 'eval']\n",
    "\n",
    "#merge the majors on the training set\n",
    "training_full = training.merge(training_majors, on='student_id')\n",
    "\n",
    "#dropping unneccesary data columns\n",
    "training_data = training_full.drop(['course','student_id','difficulty', 'index','label'], axis=1)\n",
    "testing_data = testing.drop(['course','student_id','difficulty', 'index','label'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:652: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=10.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   19.1s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 180 out of 180 | elapsed:  1.8min finished\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#splitting the training set into training and testing by a ratio 70%-30%\n",
    "labels = np.array(training_data['major'])\n",
    "training_new1= training_data.drop('major', axis = 1)\n",
    "feature_list = list(training_new1.columns)\n",
    "training_new1 = np.array(training_new1)\n",
    "\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(training_new1, labels, test_size = 0.30)\n",
    "\n",
    "#Using random forest classifier for training\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "#Grid-Search on a few parameters of Random Forest\n",
    "n_estimators = [200, 300, 400]\n",
    "max_features = ['log2', 'sqrt']\n",
    "max_depth = [7, 8, 9]\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "              }\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 10, n_jobs = -1, verbose = 2)\n",
    "\n",
    "#fitting the model\n",
    "grid_search.fit(train_features, train_labels)\n",
    "\n",
    "#storing the cross-val results\n",
    "crossval_results = grid_search.cv_results_\n",
    "\n",
    "#store means for all 10 folds\n",
    "means = grid_search.cv_results_['mean_test_score']\n",
    "\n",
    "#get the best parameters\n",
    "best = grid_search.best_params_\n",
    "\n",
    "#The best parametrs I got were n_estimators = 400, max_features='auto', max_depth= 9\n",
    "rf2 = RandomForestClassifier(n_estimators= best['n_estimators'], max_features = best['max_features'], max_depth=best['max_depth'])\n",
    "rf2.fit(train_features,train_labels)\n",
    "\n",
    "#Obtaining training and testing accuracy\n",
    "score_train = rf2.score(train_features, train_labels)\n",
    "score_test = rf2.score(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediciton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#predict model results on testing data\n",
    "predict = rf2.predict(testing_data)\n",
    "\n",
    "#store the probabilities of test data for each class\n",
    "prob = rf2.predict_proba(testing_data)\n",
    "\n",
    "#to find the corresponding classes, and chose top three classes\n",
    "classes = rf2.classes_\n",
    "dictionary_object = list(np.array([zip(classes, p) for p in prob]))\n",
    "\n",
    "l = []\n",
    "for d in dictionary_object:\n",
    "    sorted_data = sorted(d, key=lambda tup: tup[1], reverse = True)\n",
    "    l.append(sorted_data[0:3])\n",
    "    \n",
    "#after sorting data in descending order, we obtain top three majors\n",
    "testing['major1'] = [row[0][0] for row in l]\n",
    "testing['major2'] = [row[1][0] for row in l]\n",
    "testing['major3'] = [row[2][0] for row in l]\n",
    "\n",
    "#left-merge to original evals data\n",
    "temp = evals.drop(['major1','major2','major3'], axis=1)\n",
    "temp = temp.merge(testing, how='left', on='student_id')\n",
    "temp1 = temp.iloc[:,:4]\n",
    "temp2 = temp.iloc[:,123:126]\n",
    "result = temp1.join(temp2)\n",
    "\n",
    "#final result \n",
    "result = result.rename(index=str, columns={'course_x': 'course', 'grade_x':'grade'})\n",
    "result.to_csv('/Users/akankshabhattacharyya/Downloads/Project_job/assignment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
